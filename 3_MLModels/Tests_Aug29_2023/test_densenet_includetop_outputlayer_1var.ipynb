{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c99eff4-125a-49ef-afaf-558b0df7144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:07:05.317585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import copy\n",
    "from datetime import datetime, timedelta\n",
    "from keras.utils import to_categorical\n",
    "# import visualkeras\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3de435-d5d1-4c9f-a3ae-8cb02b3823d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/glade/u/home/jhayron/WR_Predictability/3_MLModels/\")\n",
    "from model_builders_v2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c43fd-d289-4bab-b0e0-7a67ddcc3861",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65e0089-54e7-4056-9265-2504ea04161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_tf_datasets(input_data, output_data):\n",
    "#     # Convert xarray dataset to numpy array for TensorFlow Dataset\n",
    "#     input_images = input_data.transpose('time', 'lat', 'lon','channel').values\n",
    "#     output_one_hot = output_data.values\n",
    "\n",
    "#     # Create TensorFlow Datasets\n",
    "#     input_dataset = tf.data.Dataset.from_tensor_slices(input_images)\n",
    "#     output_dataset = tf.data.Dataset.from_tensor_slices(output_one_hot)\n",
    "\n",
    "#     # Combine input and output datasets into a joint dataset\n",
    "#     joint_dataset = tf.data.Dataset.zip((input_dataset, output_dataset))\n",
    "\n",
    "#     return joint_dataset\n",
    "def create_tf_datasets(input_data, output_data):\n",
    "    # Convert xarray dataset to numpy array for TensorFlow Dataset\n",
    "    input_images = input_data.transpose('time', 'lat', 'lon','channel').values\n",
    "    output_one_hot = output_data.values\n",
    "\n",
    "    # Create TensorFlow Datasets\n",
    "    input_dataset = tf.data.Dataset.from_tensor_slices(input_images)\n",
    "    output_dataset = tf.data.Dataset.from_tensor_slices(output_one_hot)\n",
    "\n",
    "    # Combine input and output datasets into a joint dataset\n",
    "    joint_dataset = tf.data.Dataset.zip((input_dataset, output_dataset))\n",
    "\n",
    "    return (input_images,output_one_hot)\n",
    "\n",
    "def create_datasets(input_anoms, var_name, df_shifts, week_out):\n",
    "# Assuming you have the xarray.Dataset 'input_data' and the pandas.Series 'output_data'\n",
    "    input_data = copy.deepcopy(input_anoms[var_name])\n",
    "\n",
    "    array_temp = input_data.data\n",
    "    array_temp[np.isfinite(array_temp)==False]=0\n",
    "    input_data.data = array_temp\n",
    "\n",
    "#     input_data = (input_data - input_data.mean('time')) / (input_data.std('time'))\n",
    "    \n",
    "#     input_data[np.isfinite(array_temp)==False] = 0\n",
    "    \n",
    "    # Reshape the data to add a new dimension\n",
    "    values_reshaped = input_data.values.reshape(input_data.shape[0], input_data.shape[1], input_data.shape[2], 1)\n",
    "\n",
    "    # Create a new xarray.DataArray with the reshaped data and the original coordinates\n",
    "    input_data = xr.DataArray(values_reshaped, coords=input_data.coords, dims=('time', 'lat', 'lon', 'channel'))\n",
    "    output_data = copy.deepcopy(df_shifts[f'week{week_out}']).dropna()\n",
    "\n",
    "    # Step 1: Create a common date index that includes all dates in both the input and output data\n",
    "    common_dates = np.intersect1d(input_data['time'].values, output_data.index)\n",
    "\n",
    "    # Step 2: Reindex the input xarray dataset and the output DataFrame to the common date index\n",
    "    input_data = input_data.sel(time=common_dates)\n",
    "    output_data = output_data.loc[common_dates]\n",
    "\n",
    "    # Step 3: One-hot encode the output DataFrame using to_categorical\n",
    "    num_classes = len(output_data.unique())  # Number of classes (number of weeks in this case)\n",
    "    output_data_encoded = to_categorical(output_data, num_classes=num_classes)\n",
    "    output_data_encoded = pd.DataFrame(output_data_encoded,index=output_data.index)\n",
    "\n",
    "    # Step 4: Create masks for training, validation, and testing periods\n",
    "    train_mask = (output_data.index >= '1980-01-01') & (output_data.index <= '2010-12-31')\n",
    "    val_mask = (output_data.index >= '2011-01-01') & (output_data.index <= '2015-12-31')\n",
    "    test_mask = (output_data.index >= '2016-01-01') & (output_data.index <= '2020-12-31')\n",
    "\n",
    "    # Step 5: Split the input xarray dataset and the output DataFrame into subsets\n",
    "    input_train = input_data.sel(time=train_mask)\n",
    "    input_val = input_data.sel(time=val_mask)\n",
    "    input_test = input_data.sel(time=test_mask)\n",
    "\n",
    "    output_train = output_data_encoded.loc[train_mask]\n",
    "    output_val = output_data_encoded.loc[val_mask]\n",
    "    output_test = output_data_encoded.loc[test_mask]\n",
    "\n",
    "    train_joint_dataset = create_tf_datasets(input_train, output_train)\n",
    "    val_joint_dataset = create_tf_datasets(input_val, output_val)\n",
    "    test_joint_dataset = create_tf_datasets(input_test, output_test)\n",
    "\n",
    "    # buffer_size = train_joint_dataset.cardinality()\n",
    "    # train_joint_dataset = train_joint_dataset.shuffle(buffer_size)\n",
    "    return train_joint_dataset, val_joint_dataset, test_joint_dataset\n",
    "\n",
    "def get_output_from_dataset(dataset):\n",
    "    output_array = []\n",
    "    for input_data, output_data in dataset.as_numpy_iterator():\n",
    "        output_array.append(output_data)\n",
    "\n",
    "    # Convert the list of NumPy arrays into a single NumPy array\n",
    "    output_array = np.array(output_array)\n",
    "    return output_array\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    return tf.py_function(balanced_accuracy_score, (y_true, y_pred), tf.float32)\n",
    "\n",
    "def logging_callback(study, frozen_trial):\n",
    "    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "    if previous_best_value != study.best_value:\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        print(\n",
    "            \"Trial {} finished with best value: {} and parameters: {}. \".format(\n",
    "            frozen_trial.number,\n",
    "            frozen_trial.value,\n",
    "            frozen_trial.params,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26d5758-dfcf-475f-ab31-1b2e14c0c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets_multichannel(input_data, df_shifts, week_out):\n",
    "# Assuming you have the xarray.Dataset 'input_data' and the pandas.Series 'output_data'\n",
    "\n",
    "    # Create a new xarray.DataArray with the reshaped data and the original coordinates\n",
    "    output_data = copy.deepcopy(df_shifts[f'week{week_out}']).dropna()\n",
    "\n",
    "    # Step 1: Create a common date index that includes all dates in both the input and output data\n",
    "    common_dates = np.intersect1d(input_data['time'].values, output_data.index)\n",
    "\n",
    "    # Step 2: Reindex the input xarray dataset and the output DataFrame to the common date index\n",
    "    input_data = input_data.sel(time=common_dates)\n",
    "    output_data = output_data.loc[common_dates]\n",
    "\n",
    "    # Step 3: One-hot encode the output DataFrame using to_categorical\n",
    "    num_classes = len(output_data.unique())  # Number of classes (number of weeks in this case)\n",
    "    output_data_encoded = to_categorical(output_data, num_classes=num_classes)\n",
    "    output_data_encoded = pd.DataFrame(output_data_encoded,index=output_data.index)\n",
    "\n",
    "    # Step 4: Create masks for training, validation, and testing periods\n",
    "    train_mask = (output_data.index >= '1980-01-01') & (output_data.index <= '2010-12-31')\n",
    "    val_mask = (output_data.index >= '2011-01-01') & (output_data.index <= '2015-12-31')\n",
    "    test_mask = (output_data.index >= '2016-01-01') & (output_data.index <= '2020-12-31')\n",
    "\n",
    "    # Step 5: Split the input xarray dataset and the output DataFrame into subsets\n",
    "    input_train = input_data.sel(time=train_mask)\n",
    "    input_val = input_data.sel(time=val_mask)\n",
    "    input_test = input_data.sel(time=test_mask)\n",
    "\n",
    "    output_train = output_data_encoded.loc[train_mask]\n",
    "    output_val = output_data_encoded.loc[val_mask]\n",
    "    output_test = output_data_encoded.loc[test_mask]\n",
    "\n",
    "    train_joint_dataset = create_tf_datasets(input_train, output_train)\n",
    "    val_joint_dataset = create_tf_datasets(input_val, output_val)\n",
    "    test_joint_dataset = create_tf_datasets(input_test, output_test)\n",
    "\n",
    "    return train_joint_dataset, val_joint_dataset, test_joint_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989471a-eaaa-43c5-8f51-599709071288",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c479563a-1e9e-4926-b735-a3ea74f46c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:07:16.573060: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-29 12:07:16.574530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-08-29 12:07:16.626804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-08-29 12:07:16.626853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-29 12:07:16.692793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-29 12:07:16.692898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-08-29 12:07:16.729027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-29 12:07:16.787463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-29 12:07:16.845175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-29 12:07:16.879007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-08-29 12:07:16.930862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-08-29 12:07:16.931713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "## GLOBAL SEED ##    \n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebafd86b-e251-4679-84d1-00e6525bac7f",
   "metadata": {},
   "source": [
    "IC_SODA.nc   OHC100_SODA.nc  OHC50_SODA.nc   SD_ERA5.nc      SST_SODA.nc       STL_7cm_ERA5.nc   SWVL_28cm_ERA5.nc  U10_ERA5.nc\n",
    "IT_SODA.nc   OHC200_SODA.nc  OHC700_SODA.nc  SSH_SODA.nc     STL_1m_ERA5.nc    STL_full_ERA5.nc  SWVL_7cm_ERA5.nc   U200_ERA5.nc\n",
    "MLD_SODA.nc  OHC300_SODA.nc  OLR_ERA5.nc     SST_OISSTv2.nc  STL_28cm_ERA5.nc  SWVL_1m_ERA5.nc   SWVL_full_ERA5.nc  Z500_ERA5.ncm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5d8577-3dbe-4062-9a39-f63fc66ef446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:07:45.572526: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-29 12:07:45.572654: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-29 12:07:45.573239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-08-29 12:07:45.573339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-29 12:07:45.573381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-29 12:07:45.573392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-08-29 12:07:45.573403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-29 12:07:45.573414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-29 12:07:45.573425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-29 12:07:45.573438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-08-29 12:07:45.573449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-08-29 12:07:45.574019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-08-29 12:07:45.574060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-29 12:07:46.296305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-29 12:07:46.296350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-08-29 12:07:46.296360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-08-29 12:07:46.297575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "names_vars = ['Z500_ERA5']\n",
    "\n",
    "path_weekly_anoms = '/glade/scratch/jhayron/Data4Predictability/WeeklyAnoms_DetrendedStd/'\n",
    "# path_weekly_anoms = '/glade/scratch/jhayron/Data4Predictability/WeeklyAnoms_Std_withTrends/'\n",
    "\n",
    "list_input_anoms = []\n",
    "\n",
    "var_names = []\n",
    "for name_var in names_vars:\n",
    "    list_input_anoms.append(xr.open_dataset(f'{path_weekly_anoms}{name_var}.nc'))\n",
    "    var_names.append(list(list_input_anoms[-1].data_vars.keys())[0])\n",
    "    \n",
    "full_input_array = np.zeros((list_input_anoms[0][var_names[0]].values.shape[0],240,720,len(list_input_anoms)))\n",
    "\n",
    "for ichannel in range(len(list_input_anoms)):\n",
    "    full_input_array[:,:,:,ichannel] = list_input_anoms[ichannel][var_names[ichannel]].values\n",
    "    \n",
    "full_input_array[np.isfinite(full_input_array)==False]=0\n",
    "\n",
    "da_input = xr.DataArray(\n",
    "    data=full_input_array,\n",
    "    dims=[\"time\",\"lat\", \"lon\",\"channel\"],\n",
    "    coords=dict(\n",
    "        time=([\"time\"], list_input_anoms[0][var_names[0]].time.values),\n",
    "        lat=([\"lat\"], list_input_anoms[0][var_names[0]].lat.values),\n",
    "        lon=([\"lon\"], list_input_anoms[0][var_names[0]].lon.values),\n",
    "        channel=([\"channel\"], np.arange(full_input_array.shape[-1])),\n",
    "    )\n",
    ")\n",
    "\n",
    "del(full_input_array)\n",
    "del(list_input_anoms)\n",
    "del(var_names)\n",
    "\n",
    "week_out=3\n",
    "week_out_str = f'week{week_out}'\n",
    "\n",
    "wr_series = pd.read_csv('/glade/work/jhayron/Data4Predictability/WR_Series_20230824.csv',\\\n",
    "                index_col=0,names=['week0'],skiprows=1,parse_dates=True)\n",
    "for wk in range(2,10):\n",
    "    series_temp = copy.deepcopy(wr_series[\"week0\"])\n",
    "    series_temp.index = series_temp.index - timedelta(weeks = wk-1)\n",
    "    series_temp.name = f'week{wk-1}'\n",
    "    if wk==2:\n",
    "        df_shifts = pd.concat([pd.DataFrame(wr_series[\"week0\"]),pd.DataFrame(series_temp)],axis=1)  \n",
    "    else:\n",
    "        df_shifts = pd.concat([df_shifts,pd.DataFrame(series_temp)],axis=1)\n",
    "        \n",
    "train_joint_dataset, val_joint_dataset, test_joint_dataset = \\\n",
    "    create_datasets_multichannel(da_input, df_shifts, week_out)\n",
    "del(da_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef18836c-dbba-4bcc-92ad-d2020305d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '/glade/work/jhayron/Data4Predictability/models/CNN_Aug29_2023/test_densenet_1var/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ccf8707-29ed-4304-adae-d960993e4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_random = np.arange(len(train_joint_dataset[0]))\n",
    "np.random.shuffle(index_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239f216f-d964-4a87-8d06-01bcffd9ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predesigned_model(name_model,type_pooling,do,md,activation,input_shape):\n",
    "    num_classes = 5\n",
    "    if activation == 'LeakyReLU':\n",
    "        activation_conv= LeakyReLU()\n",
    "    elif activation == 'ReLU':\n",
    "        activation_conv= ReLU()\n",
    "        \n",
    "    model = Sequential()\n",
    "    if name_model=='resnet50':\n",
    "        model.add(ResNet50V2(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='resnet101':\n",
    "        model.add(ResNet101V2(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='xception':\n",
    "        model.add(Xception(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='inception':\n",
    "        model.add(InceptionV3(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='densenet':\n",
    "        model.add(DenseNet201(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='mobilenet':\n",
    "        model.add(MobileNetV2(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='vgg16':\n",
    "        model.add(VGG16(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='vgg19':\n",
    "        model.add(VGG19(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    \n",
    "    model.add(Dropout(do))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(num_classes*md*md, activation=activation_conv))\n",
    "    model.add(Dense(num_classes*md, activation=activation_conv))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f94ab23-00ed-4e7f-8099-af4076f1627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predesigned_model(name_model,type_pooling,do,md,activation,input_shape):\n",
    "    num_classes = 5\n",
    "    if activation == 'LeakyReLU':\n",
    "        activation_conv= LeakyReLU()\n",
    "    elif activation == 'ReLU':\n",
    "        activation_conv= ReLU()\n",
    "        \n",
    "    model = Sequential()\n",
    "    if name_model=='resnet50':\n",
    "        model.add(ResNet50V2(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='resnet101':\n",
    "        model.add(ResNet101V2(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='xception':\n",
    "        model.add(Xception(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='inception':\n",
    "        model.add(InceptionV3(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='densenet':\n",
    "        model.add(DenseNet201(weights=None, include_top=True, input_shape=input_shape,pooling=type_pooling, classes=5))\n",
    "    if name_model=='mobilenet':\n",
    "        model.add(MobileNetV2(weights=None, include_top=True, input_shape=input_shape,pooling=type_pooling, classes=5))\n",
    "    if name_model=='vgg16':\n",
    "        model.add(VGG16(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    if name_model=='vgg19':\n",
    "        model.add(VGG19(weights=None, include_top=False, input_shape=input_shape,pooling=type_pooling))\n",
    "    \n",
    "#     model.add(Dropout(do))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "\n",
    "#     model.add(Dense(num_classes*md*md, activation=activation_conv))\n",
    "#     model.add(Dense(num_classes*md, activation=activation_conv))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "840767ba-4a79-48e6-93f2-837353b931a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:08:43.033205: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-08-29 12:08:43.033922: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:08:58.112414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-29 12:08:58.424451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 85s 659ms/step - loss: 1.7575 - balanced_accuracy: 0.2146 - accuracy: 0.2150 - val_loss: 1.7173 - val_balanced_accuracy: 0.1627 - val_accuracy: 0.1743\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 58s 591ms/step - loss: 1.6161 - balanced_accuracy: 0.2194 - accuracy: 0.2531 - val_loss: 2418.8286 - val_balanced_accuracy: 0.1941 - val_accuracy: 0.2126\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 58s 592ms/step - loss: 1.6432 - balanced_accuracy: 0.1983 - accuracy: 0.2201 - val_loss: 14.5412 - val_balanced_accuracy: 0.1994 - val_accuracy: 0.2184\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 58s 590ms/step - loss: 1.6562 - balanced_accuracy: 0.1948 - accuracy: 0.2190 - val_loss: 101.5642 - val_balanced_accuracy: 0.1633 - val_accuracy: 0.1762\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 58s 592ms/step - loss: 1.6650 - balanced_accuracy: 0.2051 - accuracy: 0.1944 - val_loss: 14.8047 - val_balanced_accuracy: 0.1941 - val_accuracy: 0.2126\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 58s 590ms/step - loss: 1.6381 - balanced_accuracy: 0.1986 - accuracy: 0.2193 - val_loss: 15614.1631 - val_balanced_accuracy: 0.2137 - val_accuracy: 0.1379\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 58s 588ms/step - loss: 1.6545 - balanced_accuracy: 0.2115 - accuracy: 0.2191 - val_loss: 1.6837 - val_balanced_accuracy: 0.2213 - val_accuracy: 0.2471\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 58s 591ms/step - loss: 1.6411 - balanced_accuracy: 0.1926 - accuracy: 0.1978 - val_loss: 13.2541 - val_balanced_accuracy: 0.1941 - val_accuracy: 0.1360\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 58s 590ms/step - loss: 1.6441 - balanced_accuracy: 0.1995 - accuracy: 0.1835 - val_loss: 248.4259 - val_balanced_accuracy: 0.2137 - val_accuracy: 0.2414\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 58s 590ms/step - loss: 1.6438 - balanced_accuracy: 0.2123 - accuracy: 0.2092 - val_loss: 10.3671 - val_balanced_accuracy: 0.1941 - val_accuracy: 0.2126\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 58s 591ms/step - loss: 1.6472 - balanced_accuracy: 0.2104 - accuracy: 0.1836 - val_loss: 2.1817 - val_balanced_accuracy: 0.1953 - val_accuracy: 0.1513\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 58s 593ms/step - loss: 1.6513 - balanced_accuracy: 0.2028 - accuracy: 0.1843 - val_loss: 1.8634 - val_balanced_accuracy: 0.1966 - val_accuracy: 0.1916\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 58s 593ms/step - loss: 1.6501 - balanced_accuracy: 0.1976 - accuracy: 0.1976 - val_loss: 1.6523 - val_balanced_accuracy: 0.2060 - val_accuracy: 0.2069\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 58s 591ms/step - loss: 1.6383 - balanced_accuracy: 0.2150 - accuracy: 0.2155 - val_loss: 4.6232 - val_balanced_accuracy: 0.2018 - val_accuracy: 0.1743\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 58s 592ms/step - loss: 1.6534 - balanced_accuracy: 0.2111 - accuracy: 0.1968 - val_loss: 1.6425 - val_balanced_accuracy: 0.1875 - val_accuracy: 0.1992\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 58s 591ms/step - loss: 1.6225 - balanced_accuracy: 0.2167 - accuracy: 0.2230 - val_loss: 1.6120 - val_balanced_accuracy: 0.2012 - val_accuracy: 0.2184\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 58s 590ms/step - loss: 1.6280 - balanced_accuracy: 0.2079 - accuracy: 0.1873 - val_loss: 1.6017 - val_balanced_accuracy: 0.2083 - val_accuracy: 0.2433\n"
     ]
    }
   ],
   "source": [
    "## Parameters\n",
    "\n",
    "dict_params = {'model_base':'densenet',\n",
    "               'type_pooling':'avg',\n",
    "               'do':0.5,\n",
    "               'md':8,\n",
    "               'activation':'LeakyReLU',\n",
    "               'weighted_loss':True,\n",
    "               'bs':32,\n",
    "               'lr':0.001,\n",
    "               'input_shape':train_joint_dataset[0].shape[1:]}\n",
    "\n",
    "# with strategy.scope():\n",
    "model = build_predesigned_model(dict_params['model_base'],\n",
    "                                dict_params['type_pooling'],\n",
    "                                dict_params['do'],\n",
    "                                dict_params['md'],\n",
    "                                dict_params['activation'],\n",
    "                                dict_params['input_shape'])\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adam(lr=dict_params['lr']),\n",
    "              metrics=[balanced_accuracy,'accuracy'])  \n",
    "\n",
    "epochs = 100\n",
    "early_stopping_patience = 10\n",
    "\n",
    "# Create the EarlyStopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_balanced_accuracy',  # Metric to monitor\n",
    "    patience=early_stopping_patience,  # Number of epochs with no improvement\n",
    "    restore_best_weights=True  # Restore the weights of the best model\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "try:\n",
    "    os.mkdir(f'{path_models}{name_var}')\n",
    "except: pass\n",
    "\n",
    "filepath = f'{path_models}{name_var}/model_{week_out_str}_v0.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                             mode='auto',save_weights_only=False)\n",
    "\n",
    "if dict_params['weighted_loss']==True:\n",
    "\n",
    "    y_train = copy.deepcopy(train_joint_dataset[1])\n",
    "    y_train_integers = np.argmax(y_train, axis=1)\n",
    "    class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y_train_integers),\n",
    "                                         y = y_train_integers)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    history = model.fit(\n",
    "        train_joint_dataset[0][index_random],\n",
    "        train_joint_dataset[1][index_random],\n",
    "        batch_size=dict_params['bs'],\n",
    "        validation_data=val_joint_dataset,\n",
    "        class_weight = d_class_weights,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint,early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        train_joint_dataset[0][index_random],\n",
    "        train_joint_dataset[1][index_random],\n",
    "        batch_size=dict_params['bs'],\n",
    "        validation_data=val_joint_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint,early_stopping_callback],\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c391756-54ad-44e0-b050-174f4eb78ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 - 0.2325156182050705\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8bf919c-5224-4c8f-ac83-dc22b89f664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 162ms/step - loss: 1.6415 - balanced_accuracy: 0.2029 - accuracy: 0.2352\n",
      "test_balanced_accuracy 0.20291906595230103\n",
      "test_accuracy 0.23517785966396332\n",
      "val_balanced_accuracy 0.22126200795173645\n",
      "val_accuracy 0.24712643027305603\n"
     ]
    }
   ],
   "source": [
    "# test_loss, test_balanced_accuracy, test_accuracy = model.evaluate(test_joint_dataset.batch(len(test_joint_dataset)/5))\n",
    "test_loss, test_balanced_accuracy, test_accuracy = model.evaluate(test_joint_dataset[0],test_joint_dataset[1])\n",
    "# test_loss, test_balanced_accuracy, test_accuracy = model.evaluate(test_joint_dataset)\n",
    "val_balanced_accuracy = np.max(history.history['val_balanced_accuracy'])\n",
    "val_accuracy = np.max(history.history['val_accuracy'])\n",
    "\n",
    "print('test_balanced_accuracy',test_balanced_accuracy)\n",
    "print('test_accuracy',test_accuracy)\n",
    "print('val_balanced_accuracy',val_balanced_accuracy)\n",
    "print('val_accuracy',val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd9c80-dd79-4252-b775-5a197c63a368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_wr]",
   "language": "python",
   "name": "conda-env-cnn_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

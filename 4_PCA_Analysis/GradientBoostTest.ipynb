{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c3a39d-23a6-46d4-a4d2-72d44483acb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 06:24:53.307045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import copy\n",
    "from datetime import datetime, timedelta\n",
    "from keras.utils import to_categorical\n",
    "# import visualkeras\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob \n",
    "\n",
    "sys.path.append(\"/glade/u/home/jhayron/WR_Predictability/3_MLModels/\")\n",
    "from model_builders_v2 import *\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f43428-0c28-4c4e-a6df-9822076b2fe3",
   "metadata": {},
   "source": [
    "# Load outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbffb696-6f6c-44bc-87a0-2a1864eeb3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_out=0\n",
    "week_out_str = f'week{week_out}'\n",
    "\n",
    "wr_series = pd.read_csv('/glade/work/jhayron/Data4Predictability/WR_Series_20230824.csv',\\\n",
    "                index_col=0,names=['week0'],skiprows=1,parse_dates=True)\n",
    "for wk in range(2,10):\n",
    "    series_temp = copy.deepcopy(wr_series[\"week0\"])\n",
    "    series_temp.index = series_temp.index - timedelta(weeks = wk-1)\n",
    "    series_temp.name = f'week{wk-1}'\n",
    "    if wk==2:\n",
    "        df_shifts = pd.concat([pd.DataFrame(wr_series[\"week0\"]),pd.DataFrame(series_temp)],axis=1)  \n",
    "    else:\n",
    "        df_shifts = pd.concat([df_shifts,pd.DataFrame(series_temp)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbdec5-2d20-42a4-9808-c150b065c906",
   "metadata": {},
   "source": [
    "# Load inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20197fc5-4426-4ab7-8e86-da7cec24bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_folders = np.sort(glob.glob('/glade/u/home/jhayron/WR_Predictability/4_PCA_Analysis/figures/*/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb22def8-a75e-4deb-a1f6-2c6f652bf1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vars = [list_folders[i].split('/')[-2] for i in range(len(list_folders))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f2b61c-5347-4168-acef-d9bd6a87d4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IC_SODA',\n",
       " 'IT_SODA',\n",
       " 'MLD_SODA',\n",
       " 'OHC100_SODA',\n",
       " 'OHC200_SODA',\n",
       " 'OHC300_SODA',\n",
       " 'OHC50_SODA',\n",
       " 'OHC700_SODA',\n",
       " 'OLR_ERA5',\n",
       " 'SD_ERA5',\n",
       " 'SSH_SODA',\n",
       " 'SST_OISSTv2',\n",
       " 'SST_SODA',\n",
       " 'STL_1m_ERA5',\n",
       " 'STL_28cm_ERA5',\n",
       " 'STL_7cm_ERA5',\n",
       " 'STL_full_ERA5',\n",
       " 'SWVL_1m_ERA5',\n",
       " 'SWVL_28cm_ERA5',\n",
       " 'SWVL_7cm_ERA5',\n",
       " 'SWVL_full_ERA5',\n",
       " 'U10_ERA5',\n",
       " 'U200_ERA5',\n",
       " 'Z500_ERA5',\n",
       " 'Z500_ERA5_Region']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d975f9b7-165f-433f-98c7-54f684008d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_atmosphere = np.array([8,21,22,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd92acd-528c-4455-a07f-fab23c637788",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_inputs = {}\n",
    "for ivar in indices_atmosphere:\n",
    "    dic_inputs[list_vars[ivar]] = pd.read_csv(f'{list_folders[ivar]}PC_{list_vars[ivar]}.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc64e3f5-bb5c-4886-8081-b6b46bf7f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the dictionary and concatenate the dataframes\n",
    "for key, data in dic_inputs.items():\n",
    "    # Convert the dictionary for the current key into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    # Concatenate the current DataFrame with the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc8cf1e-5616-48d2-b7ce-8a90e1035101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OLR_ERA5':                    0         1         2         3         4         5\n",
       " 1981-01-05 -0.968588 -0.238542 -1.333144  1.923289 -2.598784  0.909056\n",
       " 1981-01-08 -1.016249 -0.018750 -2.139704  1.658078 -2.874292  1.259667\n",
       " 1981-01-12 -0.689263  0.246856 -2.087065  1.259903 -3.305622  1.411027\n",
       " 1981-01-15 -0.179971  0.155327 -2.092652  0.474640 -2.836408  1.346053\n",
       " 1981-01-19 -0.121285 -0.067485 -2.469213  0.299682 -2.099917  0.905846\n",
       " ...              ...       ...       ...       ...       ...       ...\n",
       " 2020-11-12 -0.255296 -0.034393  0.695331  0.474000 -0.196351 -0.176301\n",
       " 2020-11-16  0.733943 -0.508264 -0.100867  0.688417 -1.075825 -0.689831\n",
       " 2020-11-19  1.059217 -0.894245  0.149965  0.902031 -1.813075 -0.881752\n",
       " 2020-11-23 -0.179422 -1.250273  1.378278  1.053626 -1.705519 -0.587166\n",
       " 2020-11-26 -0.730713 -1.386602  1.347865  1.329752 -1.176415  0.056545\n",
       " \n",
       " [4164 rows x 6 columns],\n",
       " 'U10_ERA5':                    0         1         2         3         4         5\n",
       " 1981-01-05 -0.688428  1.189311  0.321077  1.394219 -1.335133  1.110825\n",
       " 1981-01-08 -0.630081  1.142316  0.091940  1.522447 -1.061075  0.943086\n",
       " 1981-01-12 -0.585736  1.183950 -0.281186  1.135133 -0.895851  0.680574\n",
       " 1981-01-15 -0.577777  1.115738 -0.627701  0.815833 -0.695563  0.519038\n",
       " 1981-01-19 -0.584967  0.609754 -1.761689  0.558110 -0.293741  0.351542\n",
       " ...              ...       ...       ...       ...       ...       ...\n",
       " 2020-11-12 -0.703587  0.767532  1.487547  1.554434 -0.336070 -0.895336\n",
       " 2020-11-16 -0.691276  0.537647  1.346807  1.893996 -0.168218 -0.454591\n",
       " 2020-11-19 -0.695557  0.572147  1.511555  2.027049  0.057221  0.016089\n",
       " 2020-11-23 -0.739259  0.897397  2.677062  1.781749  0.385706  0.241160\n",
       " 2020-11-26 -0.764454  1.053310  2.898819  1.289312  0.276869 -0.072079\n",
       " \n",
       " [4164 rows x 6 columns],\n",
       " 'U200_ERA5':                    0         1         2         3         4         5\n",
       " 1981-01-05  0.090230 -1.963035 -1.179718 -1.002937 -1.554858  0.394908\n",
       " 1981-01-08  0.163777 -2.064337 -1.089257 -0.877637 -1.332512  0.146720\n",
       " 1981-01-12  0.818560 -1.761364 -0.448252 -1.099787 -1.873348 -0.219231\n",
       " 1981-01-15  0.918830 -1.730463 -0.369533 -1.144669 -1.721956 -0.397410\n",
       " 1981-01-19  0.260165 -1.877993 -1.003531 -0.904120 -1.721897 -0.442259\n",
       " ...              ...       ...       ...       ...       ...       ...\n",
       " 2020-11-12 -1.166902 -0.689788  0.360323  1.879983  0.012422  1.566612\n",
       " 2020-11-16 -0.993346 -0.514747 -0.783865  0.713899 -0.625193  3.109328\n",
       " 2020-11-19 -0.957191 -0.164105 -0.438094  0.380518 -1.160067  3.032385\n",
       " 2020-11-23 -1.327391 -0.819804  0.514013  0.344986 -1.445916  1.682575\n",
       " 2020-11-26 -1.378034 -1.572208  0.608251  0.159743 -1.296168  0.894720\n",
       " \n",
       " [4164 rows x 6 columns],\n",
       " 'Z500_ERA5':                    0         1         2         3         4         5\n",
       " 1981-01-05 -0.435789 -0.686555  1.526521 -1.219271 -1.404930 -0.673287\n",
       " 1981-01-08 -0.264601 -0.876021  1.789623 -1.042864 -1.526212 -1.054127\n",
       " 1981-01-12  0.206661 -0.967765  1.204811 -1.398351 -1.706147 -1.417993\n",
       " 1981-01-15  0.296756 -0.998281  0.757838 -0.765516 -2.066411 -0.748929\n",
       " 1981-01-19  0.156047 -1.350193  1.077894 -0.150751 -2.294708 -0.479497\n",
       " ...              ...       ...       ...       ...       ...       ...\n",
       " 2020-11-12  0.906373 -1.687870 -1.464919 -0.241182 -0.237162  0.888832\n",
       " 2020-11-16  0.514951 -1.498858 -0.253421 -0.406761  0.304698 -0.339432\n",
       " 2020-11-19  0.677344 -1.166430 -0.606556 -0.417141  1.485913 -1.339994\n",
       " 2020-11-23  0.752681 -1.085904 -1.245251 -0.254358  0.918582 -1.114843\n",
       " 2020-11-26  0.699104 -1.131089 -0.621537  0.225297 -0.851521 -0.741862\n",
       " \n",
       " [4164 rows x 6 columns]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ca361-19dd-4467-861b-d5f74d65795a",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8338d33c-cada-4e47-ac27-6b5e29280295",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_combined_df = pd.concat([combined_df,df_shifts[week_out_str]],axis=1)\n",
    "fully_combined_df = fully_combined_df.dropna()\n",
    "\n",
    "X_train = fully_combined_df['1980':'2015'].iloc[:,:-1].values\n",
    "y_train = fully_combined_df['1980':'2015'].iloc[:,-1].values\n",
    "\n",
    "# X_val = fully_combined_df['2011':'2015'].iloc[:,:-1].values\n",
    "# y_val = fully_combined_df['2011':'2015'].iloc[:,-1].values\n",
    "\n",
    "X_test = fully_combined_df['2016':'2020'].iloc[:,:-1].values\n",
    "y_test = fully_combined_df['2016':'2020'].iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f31ee8c-1e93-44f7-9785-e12e3aac4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = ensemble.GradientBoostingClassifier()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# acc_train = clf.score(X_train, y_train)\n",
    "# acc_val = clf.score(X_val, y_val)\n",
    "# acc_test = clf.score(X_test, y_test)\n",
    "# print(\"Accuracy train: {:.4f}\".format(acc_train))\n",
    "# print(\"Accuracy val: {:.4f}\".format(acc_val))\n",
    "# print(\"Accuracy test: {:.4f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d152775-10dc-4652-b2bb-b0940e5953b9",
   "metadata": {},
   "source": [
    "# optimize parameters for week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff17857b-9469-4d21-b6a7-8d92f405db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'random_state': [42],  # Set to a specific value for reproducibility\n",
    "    'criterion': ['friedman_mse', 'squared_error'],  # Splitting criterion\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.2],  # Minimum impurity decrease for split\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2],  # Minimum weighted fraction for leaf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fe5fcd1-0c99-4a92-8576-65fd05522700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the GradientBoostingClassifier\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "# Create the Grid Search object\n",
    "grid_search = RandomizedSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=18,n_iter=100,return_train_score=True)\n",
    "\n",
    "# Fit the model with training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2febed0-ce1c-4cdd-99ac-70185cdbbcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5096\n",
      "Accuracy test: 0.3867\n"
     ]
    }
   ],
   "source": [
    "acc_train = best_clf.score(X_train, y_train)\n",
    "# acc_val = best_clf.score(X_val, y_val)\n",
    "acc_test = best_clf.score(X_test, y_test)\n",
    "print(\"Accuracy train: {:.4f}\".format(acc_train))\n",
    "# print(\"Accuracy val: {:.4f}\".format(acc_val))\n",
    "print(\"Accuracy test: {:.4f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f29f7-ee42-4fd7-9c8b-ea5d87b1ef2b",
   "metadata": {},
   "source": [
    "# Iterate atmosphere, land, ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a87a8a2-b94f-4522-a2bb-b62a84024d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IC_SODA',\n",
       " 'IT_SODA',\n",
       " 'MLD_SODA',\n",
       " 'OHC100_SODA',\n",
       " 'OHC200_SODA',\n",
       " 'OHC300_SODA',\n",
       " 'OHC50_SODA',\n",
       " 'OHC700_SODA',\n",
       " 'OLR_ERA5',\n",
       " 'SD_ERA5',\n",
       " 'SSH_SODA',\n",
       " 'SST_OISSTv2',\n",
       " 'SST_SODA',\n",
       " 'STL_1m_ERA5',\n",
       " 'STL_28cm_ERA5',\n",
       " 'STL_7cm_ERA5',\n",
       " 'STL_full_ERA5',\n",
       " 'SWVL_1m_ERA5',\n",
       " 'SWVL_28cm_ERA5',\n",
       " 'SWVL_7cm_ERA5',\n",
       " 'SWVL_full_ERA5',\n",
       " 'U10_ERA5',\n",
       " 'U200_ERA5',\n",
       " 'Z500_ERA5',\n",
       " 'Z500_ERA5_Region']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13f29dd2-b4f0-4206-a9c9-311d6506458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_atmosphere = np.array([8,21,22,23])\n",
    "indices_land = np.array([9,13,16,17,20])\n",
    "indices_ocean = np.array([0,1,2,4,6,10,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ef76b4c-237e-4c61-9c9d-c590c20cf259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['OLR_ERA5', 'U10_ERA5', 'U200_ERA5', 'Z500_ERA5'])\n",
      "1\n",
      "0.30257556734066676\n",
      "0.32941176470588235\n",
      "2\n",
      "0.24616494574892714\n",
      "0.25984251968503935\n",
      "3\n",
      "0.24507355283623483\n",
      "0.22134387351778656\n",
      "4\n",
      "0.2412405599385342\n",
      "0.19444444444444445\n",
      "5\n",
      "0.23959485036448475\n",
      "0.17729083665338646\n",
      "6\n",
      "0.24425463336019343\n",
      "0.22\n",
      "7\n",
      "0.240142420778442\n",
      "0.1746987951807229\n",
      "8\n",
      "0.24014204598691977\n",
      "0.17540322580645162\n",
      "dict_keys(['IC_SODA', 'IT_SODA', 'MLD_SODA', 'OHC200_SODA', 'OHC50_SODA', 'SSH_SODA', 'SST_SODA'])\n",
      "1\n",
      "0.23877368213931\n",
      "0.1803921568627451\n",
      "2\n",
      "0.239320877761745\n",
      "0.17716535433070865\n",
      "3\n",
      "0.23932087776174504\n",
      "0.17786561264822134\n",
      "4\n",
      "0.23959485036448475\n",
      "0.1765873015873016\n",
      "5\n",
      "0.23959485036448475\n",
      "0.17729083665338646\n",
      "6\n",
      "0.23986844817570224\n",
      "0.176\n",
      "7\n",
      "0.240142420778442\n",
      "0.1746987951807229\n",
      "8\n",
      "0.24014204598691977\n",
      "0.17540322580645162\n",
      "dict_keys(['SD_ERA5', 'STL_1m_ERA5', 'STL_full_ERA5', 'SWVL_1m_ERA5', 'SWVL_full_ERA5'])\n",
      "1\n",
      "0.23877368213931\n",
      "0.1803921568627451\n",
      "2\n",
      "0.239320877761745\n",
      "0.17716535433070865\n",
      "3\n",
      "0.23932087776174504\n",
      "0.17786561264822134\n",
      "4\n",
      "0.23959485036448475\n",
      "0.1765873015873016\n",
      "5\n",
      "0.23959485036448475\n",
      "0.17729083665338646\n",
      "6\n",
      "0.23986844817570224\n",
      "0.176\n",
      "7\n",
      "0.240142420778442\n",
      "0.1746987951807229\n",
      "8\n",
      "0.24014204598691977\n",
      "0.17540322580645162\n"
     ]
    }
   ],
   "source": [
    "for component in ['atm','ocn','lnd']:\n",
    "    if component=='atm':\n",
    "        dic_inputs = {}\n",
    "        for ivar in indices_atmosphere:\n",
    "            dic_inputs[list_vars[ivar]] = pd.read_csv(f'{list_folders[ivar]}PC_{list_vars[ivar]}.csv',index_col=0,parse_dates=True)\n",
    "    elif component =='ocn':\n",
    "        dic_inputs = {}\n",
    "        for ivar in indices_ocean:\n",
    "            dic_inputs[list_vars[ivar]] = pd.read_csv(f'{list_folders[ivar]}PC_{list_vars[ivar]}.csv',index_col=0,parse_dates=True)\n",
    "    elif component =='lnd':\n",
    "        dic_inputs = {}\n",
    "        for ivar in indices_land:\n",
    "            dic_inputs[list_vars[ivar]] = pd.read_csv(f'{list_folders[ivar]}PC_{list_vars[ivar]}.csv',index_col=0,parse_dates=True)\n",
    "    print(dic_inputs.keys())\n",
    "    # Create an empty DataFrame to store the combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through the dictionary and concatenate the dataframes\n",
    "    for key, data in dic_inputs.items():\n",
    "        # Convert the dictionary for the current key into a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        # Concatenate the current DataFrame with the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], axis=1)\n",
    "    \n",
    "    scores_test = []\n",
    "    scores_val = []\n",
    "    \n",
    "    for week_out in np.arange(1,9):\n",
    "        print(week_out)\n",
    "        week_out_str = f'week{week_out}'\n",
    "        fully_combined_df = pd.concat([combined_df,df_shifts[week_out_str]],axis=1)\n",
    "        fully_combined_df = fully_combined_df.dropna()\n",
    "\n",
    "        X_train = fully_combined_df['1980':'2015'].iloc[:,:-1].values\n",
    "        y_train = fully_combined_df['1980':'2015'].iloc[:,-1].values\n",
    "\n",
    "        X_test = fully_combined_df['2016':'2020'].iloc[:,:-1].values\n",
    "        y_test = fully_combined_df['2016':'2020'].iloc[:,-1].values\n",
    "        \n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 4, 5, 6, 7],\n",
    "            'min_samples_split': [2, 3, 4, 5],\n",
    "            'min_samples_leaf': [1, 2, 3, 4],\n",
    "            'subsample': [0.8, 0.9, 1.0],\n",
    "            'max_features': ['sqrt', 'log2', None],\n",
    "            'random_state': [42],  # Set to a specific value for reproducibility\n",
    "            'criterion': ['friedman_mse', 'squared_error'],  # Splitting criterion\n",
    "            'min_impurity_decrease': [0.0, 0.1, 0.2],  # Minimum impurity decrease for split\n",
    "            'min_weight_fraction_leaf': [0.0, 0.1, 0.2],  # Minimum weighted fraction for leaf\n",
    "        }\n",
    "        # Create the GradientBoostingClassifier\n",
    "        clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "        # Create the Grid Search object\n",
    "        grid_search = RandomizedSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=18,n_iter=100,return_train_score=True)\n",
    "\n",
    "        # Fit the model with training data\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best parameters and best estimator\n",
    "        best_params = grid_search.best_params_\n",
    "        best_clf = grid_search.best_estimator_\n",
    "        best_score = grid_search.best_score_\n",
    "        \n",
    "        scores_test.append(best_clf.score(X_test, y_test))\n",
    "        scores_val.append(best_score)\n",
    "        results = pd.DataFrame(np.array([best_clf.predict(X_test),y_test]).T,\n",
    "                     index=fully_combined_df['2016':'2020'].index,\n",
    "                     columns=['y_predicted','y_test'])\n",
    "        \n",
    "        np.save(f'results/{component}_scores_test',np.array(scores_test))\n",
    "        np.save(f'results/{component}_scores_val',np.array(scores_val))\n",
    "        print(best_score)\n",
    "        print(scores_test[-1])\n",
    "        results.to_csv(f'results/results_{component}_{week_out_str}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5af9c-06e2-4fd8-9af0-a045a73f7adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_wr]",
   "language": "python",
   "name": "conda-env-cnn_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import datetime as dt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['MLD', 'OHC100', 'OHC200', 'OHC300', 'OHC50', 'OHC700', 'SSH', 'SST',\n",
    "            'OLR', 'SD', 'STL_1m', 'STL_full', 'SWVL_1m', 'SWVL_full', 'U10', 'U200', 'Z500',\n",
    "            'IC', 'IT','SST']\n",
    "origins = ['SODA', 'SODA', 'SODA', 'SODA', 'SODA', 'SODA', 'SODA', 'SODA',\n",
    "          'ERA5', 'ERA5', 'ERA5', 'ERA5', 'ERA5', 'ERA5', 'ERA5', 'ERA5', 'ERA5',\n",
    "          'SODA', 'SODA','OISSTv2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files = '/glade/work/jhayron/Data4Predictability/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_dataset(path_files, var, origin):\n",
    "    if origin == 'ERA5':\n",
    "        path_var = f'{path_files}{origin}/Daily_05Deg/{var}/'\n",
    "    elif (origin == 'SODA'):\n",
    "        path_var = f'{path_files}{origin}_Daily/{var}/'\n",
    "    elif (origin == 'OISSTv2'):\n",
    "        path_var = f'{path_files}{origin}/{var}/'\n",
    "\n",
    "    list_files = np.sort(glob.glob(f'{path_var}*.nc'))#[4000:4010]\n",
    "    dataset = xr.open_mfdataset(list_files,combine='nested',concat_dim=\"time\")\n",
    "    if dataset.time.dtype==np.int64:\n",
    "        dataset['time'] = np.array([dt.datetime.strptime(list_files[i].split('_')[-1],'%Y-%m-%d.nc')\\\n",
    "            for i in range(len(list_files))])\n",
    "    dataset = dataset.where(dataset.time>np.datetime64('1981-01-01'),drop=True)\n",
    "    dataset = dataset.load()\n",
    "    if origin == 'SODA':\n",
    "        if 'xt_ocean' in dataset.dims:\n",
    "            dataset = dataset.rename({'xt_ocean': 'lon','yt_ocean': 'lat'})\n",
    "        elif 'xt' in dataset.dims:\n",
    "            dataset = dataset.rename({'xt': 'lon','yt': 'lat'})\n",
    "    if origin == 'OISSTv2':\n",
    "        dataset = dataset.assign_coords(lat=dataset.lat.values[:,0],lon=dataset.lon.values[0,:])\n",
    "        dataset = dataset.rename({'x': 'lon', 'y': 'lat'})\n",
    "    if origin == 'ERA5':\n",
    "        dataset = dataset.assign_coords(lat=dataset.lat.values[:,0],lon=dataset.lon.values[0,:])\n",
    "        dataset = dataset.rename({'x': 'lon', 'y': 'lat'})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_climatology(dataset,var_name_xarray,path_save_climatology):\n",
    "    dataset_clima = dataset.isel(time = (pd.to_datetime(dataset.time).year>=1981)&\\\n",
    "                                 (pd.to_datetime(dataset.time).year<=2010))\n",
    "    # return dataset_clima\n",
    "    dataset_clima = dataset_clima.isel(time = ~((pd.to_datetime(dataset_clima.time).day == 29)&((pd.to_datetime(dataset_clima.time).month == 2))))\n",
    "    \n",
    "    doy = pd.to_datetime(dataset_clima.time).day_of_year\n",
    "    climatology = []\n",
    "    for i in range(1,366):\n",
    "        climatology.append(dataset_clima.isel(time = doy == i)[var_name_xarray].mean('time'))\n",
    "    attrs = dataset[var_name_xarray].attrs\n",
    "    attrs['File Author'] = 'Jhayron S. Pérez-Carrasquilla'\n",
    "    \n",
    "    climatology = xr.Dataset({\n",
    "                 f'{var_name_xarray}_climatology': (['day_of_year','lat','lon'], np.array(climatology)),\n",
    "                },\n",
    "                 coords =\n",
    "                {'day_of_year': (['day_of_year'], np.arange(1,366)),\n",
    "                 'lat' : (['lat'], dataset.lat.values),\n",
    "                 'lon' : (['lon'], dataset.lon.values)\n",
    "                },\n",
    "                attrs = attrs)\n",
    "    \n",
    "    climatology = climatology.transpose('day_of_year','lat','lon')\n",
    "    climatology.to_netcdf(path_save_climatology)\n",
    "    return climatology\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalies(dataset,var_name_xarray,climatology,path_save_anomalies):\n",
    "    anomalies = copy.deepcopy(dataset)\n",
    "    for day in range(1,367):\n",
    "        # print(day) \n",
    "        if day == 366:\n",
    "            anomalies[var_name_xarray][{'time':(pd.to_datetime(dataset.time).day_of_year == day)}] = \\\n",
    "                (dataset[var_name_xarray].isel(time = (pd.to_datetime(dataset.time).day_of_year == day)) \\\n",
    "                - climatology[f'{var_name_xarray}_climatology'].sel(day_of_year = day-1))\n",
    "        else:\n",
    "            anomalies[var_name_xarray][{'time':(pd.to_datetime(dataset.time).day_of_year == day)}] = \\\n",
    "                (dataset[var_name_xarray].isel(time = (pd.to_datetime(dataset.time).day_of_year == day)) \\\n",
    "                - climatology[f'{var_name_xarray}_climatology'].sel(day_of_year = day))\n",
    "    anomalies = anomalies.rename({var_name_xarray:f'{var_name_xarray}_anomalies'})\n",
    "    anomalies.to_netcdf(path_save_anomalies)\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_daily_datasets = '/glade/scratch/jhayron/Data4Predictability/DailyDatasets/'\n",
    "path_daily_anoms_datasets = '/glade/scratch/jhayron/Data4Predictability/DailyAnoms/'\n",
    "path_daily_detrended_anoms = '/glade/scratch/jhayron/Data4Predictability/DailyDetrendedAnoms/'\n",
    "path_daily_climatologies = '/glade/scratch/jhayron/Data4Predictability/DailyClimatologies/'\n",
    "path_trends = '/glade/scratch/jhayron/Data4Predictability/trends/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save individual datasets per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLD\n",
      "OHC100\n"
     ]
    }
   ],
   "source": [
    "for variable_i in range(len(variables)):\n",
    "    print(variables[variable_i])\n",
    "    dataset = get_full_dataset(path_files,variables[variable_i],origins[variable_i])\n",
    "    var_name_xarray = list(dataset.data_vars.keys())[0]\n",
    "    dataset.to_netcdf(f'{path_daily_datasets}{variables[variable_i]}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_i in range(len(variables)):\n",
    "    print(variables[variable_i])\n",
    "    dataset = get_full_dataset(path_files,variables[variable_i],origins[variable_i])\n",
    "    var_name_xarray = list(dataset.data_vars.keys())[0]\n",
    "    dataset.to_netcdf(f'{path_daily_datasets}{variables[variable_i]}.nc')\n",
    "    climatology = get_climatology(dataset,var_name_xarray,f'{path_daily_climatologies}{variables[variable_i]}.nc')\n",
    "    anomalies = get_anomalies(dataset,var_name_xarray,climatology,f'{path_daily_anoms_datasets}{variables[variable_i]}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(dataset,variable,unit):\n",
    "    lat = dataset.lat.values\n",
    "    lon = dataset.lon.values\n",
    "\n",
    "    array_coefs = np.zeros([len(lat),len(lon)])\n",
    "    for lati in range(len(lat)):\n",
    "        # print(lati)\n",
    "        for loni in range(len(lon)):\n",
    "        # for loni in [0]:\n",
    "            series = dataset.sel(lat=lat[lati],lon=lon[loni])[variable]\n",
    "            X = [i for i in range(0, len(series))]\n",
    "            X = np.reshape(X, (len(X), 1))\n",
    "            y = series.values\n",
    "            try:\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                array_coefs[lati,loni] = model.coef_[0]\n",
    "            except:\n",
    "                array_coefs[lati,loni] = 0\n",
    "    trend = xr.Dataset({\n",
    "                 f'{variable}_trend': (['lat','lon'], array_coefs),\n",
    "                },\n",
    "                 coords =\n",
    "                {\n",
    "                 'lat' : (['lat'], lat),\n",
    "                 'lon' : (['lon'], lon)\n",
    "                },\n",
    "                attrs = \n",
    "                {'File Author' : 'Jhayron S. Pérez-Carrasquilla','units':f'({unit})/day'})\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join ERA5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U10\n",
      "U200\n",
      "Z500\n"
     ]
    }
   ],
   "source": [
    "for variable in ['U10','U200','Z500']:\n",
    "    print(variable)\n",
    "    path_files = f'/glade/scratch/jhayron/Data4Predictability/DailyDatasets/{variable}/'\n",
    "    files_list = np.sort(glob.glob(f'{path_files}*'))\n",
    "    dataset = xr.open_mfdataset(files_list,combine='nested',concat_dim=\"time\")\n",
    "    dataset = dataset.where(dataset.time>np.datetime64('1981-01-01'),drop=True)\n",
    "    dataset = dataset.load()\n",
    "    dataset.to_netcdf(f'/glade/scratch/jhayron/Data4Predictability/DailyDatasets/{variable}_ERA5.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset('/glade/scratch/jhayron/Data4Predictability/DailyDatasets/OHC700_SODA.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array([pd.to_datetime(dataset.time.values[i]).year for i in range(len(dataset.time))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991,\n",
       "       1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
       "       2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
       "       2015, 2016, 2017, 2018, 2019, 2020])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('1981-01-02T00:00:00.000000000')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.time.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join OHC700 SODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHC700\n"
     ]
    }
   ],
   "source": [
    "for variable in ['OHC700']:\n",
    "    print(variable)\n",
    "    path_files = f'/glade/scratch/jhayron/Data4Predictability/DailyDatasets/{variable}/'\n",
    "    files_list = np.sort(glob.glob(f'{path_files}*'))\n",
    "    dataset = xr.open_mfdataset(files_list,combine='nested',concat_dim=\"time\")\n",
    "    dataset = dataset.where(dataset.time>np.datetime64('1981-01-01'),drop=True)\n",
    "    dataset = dataset.load()\n",
    "    dataset.to_netcdf(f'/glade/scratch/jhayron/Data4Predictability/DailyDatasets/{variable}_SODA.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:weather_regimes]",
   "language": "python",
   "name": "conda-env-weather_regimes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
